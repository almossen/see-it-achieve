import { useState, useEffect, useRef } from "react";
import { supabase } from "@/integrations/supabase/client";
import { useAuth } from "@/hooks/useAuth";
import { useCart } from "@/hooks/useCart";
import { Mic, MicOff, X } from "lucide-react";
import { toast } from "sonner";
import { motion } from "framer-motion";

interface VoiceSearchProps {
  onClose: () => void;
}

// Known units with dual forms mapped to singular
const UNIT_MAP: Record<string, string> = {
  ÙƒØ±ØªÙˆÙ†ÙŠÙ†: "ÙƒØ±ØªÙˆÙ†", ÙƒÙŠÙ„ÙˆÙŠÙ†: "ÙƒÙŠÙ„Ùˆ", Ø­Ø¨ØªÙŠÙ†: "Ø­Ø¨Ø©", Ø­Ø²Ù…ØªÙŠÙ†: "Ø­Ø²Ù…Ø©",
  Ø¹Ù„Ø¨ØªÙŠÙ†: "Ø¹Ù„Ø¨Ø©", ÙƒÙŠØ³ÙŠÙ†: "ÙƒÙŠØ³", Ù„ØªØ±ÙŠÙ†: "Ù„ØªØ±", ØµÙ†Ø¯ÙˆÙ‚ÙŠÙ†: "ØµÙ†Ø¯ÙˆÙ‚",
  Ø·Ø¨Ù‚ÙŠÙ†: "Ø·Ø¨Ù‚", Ù‚Ø·Ø¹ØªÙŠÙ†: "Ù‚Ø·Ø¹Ø©", Ø±Ø¨Ø·ØªÙŠÙ†: "Ø±Ø¨Ø·Ø©",
};
const KNOWN_UNITS = ["ÙƒØ±ØªÙˆÙ†", "ÙƒÙŠÙ„Ùˆ", "Ø­Ø¨Ø©", "Ø­Ø²Ù…Ø©", "Ø¹Ù„Ø¨Ø©", "ÙƒÙŠØ³", "Ù„ØªØ±", "Ø¨Ø§ÙƒÙŠØª", "ØµÙ†Ø¯ÙˆÙ‚", "Ø±Ø¨Ø·Ø©", "Ø·Ø¨Ù‚", "Ù‚Ø·Ø¹Ø©"];

// Arabic number words â†’ numeric value
const ARABIC_NUMBERS: Record<string, number> = {
  ÙˆØ§Ø­Ø¯: 1, ÙˆØ§Ø­Ø¯Ø©: 1,
  Ø§Ø«Ù†ÙŠÙ†: 2, Ø§Ø«Ù†Ø§Ù†: 2, Ø§Ø«Ù†ØªÙŠÙ†: 2,
  Ø«Ù„Ø§Ø«Ø©: 3, Ø«Ù„Ø§Ø«: 3,
  Ø£Ø±Ø¨Ø¹Ø©: 4, Ø£Ø±Ø¨Ø¹: 4,
  Ø®Ù…Ø³Ø©: 5, Ø®Ù…Ø³: 5,
  Ø³ØªØ©: 6, Ø³Øª: 6,
  Ø³Ø¨Ø¹Ø©: 7, Ø³Ø¨Ø¹: 7,
  Ø«Ù…Ø§Ù†ÙŠØ©: 8, Ø«Ù…Ø§Ù†ÙŠ: 8, Ø«Ù…Ø§Ù†: 8,
  ØªØ³Ø¹Ø©: 9, ØªØ³Ø¹: 9,
  Ø¹Ø´Ø±Ø©: 10, Ø¹Ø´Ø±: 10,
};

function parseVoiceQuery(raw: string): { productQuery: string; detectedUnit: string | null; detectedQuantity: number } {
  let text = raw.trim();
  let detectedUnit: string | null = null;
  let detectedQuantity = 1;

  // 1. Extract leading Arabic number word (e.g. "Ø«Ù„Ø§Ø« ÙƒØ±ØªÙˆÙ† Ø®ÙŠØ§Ø±")
  for (const [word, num] of Object.entries(ARABIC_NUMBERS)) {
    if (text.startsWith(word + " ")) {
      detectedQuantity = num;
      text = text.slice(word.length + 1).trim();
      break;
    }
  }

  // 2. Extract leading numeric digit (e.g. "3 ÙƒØ±ØªÙˆÙ† Ø®ÙŠØ§Ø±")
  const digitMatch = text.match(/^(\d+)\s+/);
  if (digitMatch && detectedQuantity === 1) {
    detectedQuantity = parseInt(digitMatch[1], 10);
    text = text.slice(digitMatch[0].length).trim();
  }

  // 3. Detect dual unit forms (ÙƒÙŠÙ„ÙˆÙŠÙ† â†’ qty 2 + ÙƒÙŠÙ„Ùˆ)
  for (const [dual, singular] of Object.entries(UNIT_MAP)) {
    if (text.startsWith(dual + " ")) {
      detectedUnit = singular;
      if (detectedQuantity === 1) detectedQuantity = 2;
      text = text.slice(dual.length + 1).trim();
      break;
    }
    if (text.endsWith(" " + dual)) {
      detectedUnit = singular;
      if (detectedQuantity === 1) detectedQuantity = 2;
      text = text.slice(0, text.length - dual.length - 1).trim();
      break;
    }
  }

  // 4. Detect singular unit if not yet found
  if (!detectedUnit) {
    for (const unit of KNOWN_UNITS) {
      if (text.startsWith(unit + " ")) {
        detectedUnit = unit;
        text = text.slice(unit.length + 1).trim();
        break;
      }
      if (text.endsWith(" " + unit)) {
        detectedUnit = unit;
        text = text.slice(0, text.length - unit.length - 1).trim();
        break;
      }
    }
  }

  return { productQuery: text, detectedUnit, detectedQuantity };
}

const VoiceSearch = ({ onClose }: VoiceSearchProps) => {
  const { tenantId, user } = useAuth();
  const { addItem, updateQuantity } = useCart();
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState("");
  const [addedItems, setAddedItems] = useState<string[]>([]);
  const recognitionRef = useRef<any>(null);

  // Keep a ref to the latest handler to avoid stale closure in SpeechRecognition callbacks
  const handleVoiceResultRef = useRef<(query: string) => Promise<void>>();

  useEffect(() => {
    handleVoiceResultRef.current = async (query: string) => {
      if (!tenantId || !query.trim()) return;

      const { productQuery, detectedUnit, detectedQuantity } = parseVoiceQuery(query);

      const { data } = await supabase
        .from("products")
        .select("*")
        .eq("tenant_id", tenantId)
        .eq("is_active", true)
        .or(`name_ar.ilike.%${productQuery}%,name_en.ilike.%${productQuery}%`)
        .limit(5);

      if (data && data.length > 0) {
        const product = data[0];
        const unitLabel = detectedUnit || product.unit || "";
        addItem({
          product_id: product.id,
          name: product.name_ar,
          emoji: product.emoji,
          price: product.price,
          unit: unitLabel,
          image_url: product.image_url,
        });
        // Set quantity if more than 1
        if (detectedQuantity > 1) {
          updateQuantity(product.id, detectedQuantity);
        }
        const qtyLabel = detectedQuantity > 1 ? `${detectedQuantity} ` : "";
        setAddedItems(prev => [...prev, `âœ… ${qtyLabel}${unitLabel} ${product.name_ar}`]);
        toast.success(`ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© ${detectedQuantity > 1 ? detectedQuantity + " " : ""}${product.name_ar} Ù„Ù„Ø³Ù„Ø©`);
      } else {
        const customId = `custom_${Date.now()}`;
        const unitLabel = detectedUnit || "Ø­Ø¨Ø©";
        addItem({
          product_id: customId,
          name: productQuery,
          emoji: "ğŸ“",
          unit: unitLabel,
          is_custom: true,
        });
        if (detectedQuantity > 1) {
          updateQuantity(customId, detectedQuantity);
        }
        const qtyLabel = detectedQuantity > 1 ? `${detectedQuantity} ` : "";
        setAddedItems(prev => [...prev, `ğŸ“ ${qtyLabel}${unitLabel} ${productQuery} â€” ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©`]);
        toast.info(`ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© "${productQuery}" ÙƒÙ…Ù†ØªØ¬ Ù…Ø®ØµØµ`);

        await supabase.from("suggested_products").insert({
          tenant_id: tenantId,
          name_ar: productQuery,
          unit: detectedUnit,
          suggested_by: user?.id,
        });
      }
    };
  }, [tenantId, user, addItem, updateQuantity]);

  useEffect(() => {
    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    if (!SpeechRecognition) {
      toast.error("Ø§Ù„Ù…ØªØµÙØ­ Ù„Ø§ ÙŠØ¯Ø¹Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª");
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = "ar-SA";
    recognition.continuous = false;
    recognition.interimResults = true;

    recognition.onresult = (event: any) => {
      let finalTranscript = "";
      for (let i = 0; i < event.results.length; i++) {
        finalTranscript += event.results[i][0].transcript;
      }
      setTranscript(finalTranscript);

      if (event.results[event.results.length - 1].isFinal) {
        handleVoiceResultRef.current?.(finalTranscript);
      }
    };

    recognition.onend = () => {
      setIsListening(false);
    };

    recognition.onerror = (event: any) => {
      console.error("Speech error:", event.error);
      setIsListening(false);
      if (event.error === "not-allowed") {
        toast.error("ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†");
      }
    };

    recognitionRef.current = recognition;
    return () => { recognition.abort(); };
  }, []);

  const toggleListening = () => {
    if (isListening) {
      recognitionRef.current?.stop();
    } else {
      setTranscript("");
      recognitionRef.current?.start();
      setIsListening(true);
    }
  };

  return (
    <motion.div
      initial={{ opacity: 0 }}
      animate={{ opacity: 1 }}
      exit={{ opacity: 0 }}
      className="fixed inset-0 z-50 bg-background/95 backdrop-blur-sm flex flex-col"
    >
      {/* Header */}
      <div className="flex items-center justify-between p-4 border-b border-border">
        <h2 className="text-xl font-bold">ğŸ¤ Ø£Ø·Ù„Ø¨ Ø¨ØµÙˆØªÙƒ</h2>
        <button onClick={onClose} className="p-2">
          <X className="h-6 w-6" />
        </button>
      </div>

      {/* Mic area */}
      <div className="flex-1 flex flex-col items-center justify-center px-4">
        <button
          onClick={toggleListening}
          className={`w-32 h-32 rounded-full flex items-center justify-center transition-all ${
            isListening
              ? "bg-destructive text-destructive-foreground scale-110 shadow-2xl"
              : "bg-primary text-primary-foreground shadow-lg"
          }`}
        >
          {isListening ? (
            <MicOff className="h-14 w-14" />
          ) : (
            <Mic className="h-14 w-14" />
          )}
        </button>
        <p className="text-lg mt-6 text-center font-medium">
          {isListening ? "Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹... ØªÙƒÙ„Ù‘Ù… Ø§Ù„Ø¢Ù†" : "Ø§Ø¶ØºØ· ÙˆÙ‚Ù„ Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬"}
        </p>
        <p className="text-sm text-muted-foreground mt-1">Ù…Ø«Ø§Ù„: "ÙƒØ±ØªÙˆÙ† Ø®ÙŠØ§Ø±" Ø£Ùˆ "ÙƒÙŠÙ„Ùˆ Ø·Ù…Ø§Ø·Ù…"</p>

        {/* Transcript */}
        {transcript && (
          <motion.div
            initial={{ opacity: 0, y: 10 }}
            animate={{ opacity: 1, y: 0 }}
            className="mt-4 bg-muted rounded-xl p-4 w-full max-w-sm text-center"
          >
            <p className="text-base">ğŸ—£ï¸ {transcript}</p>
          </motion.div>
        )}
      </div>

      {/* Added items list */}
      {addedItems.length > 0 && (
        <motion.div
          initial={{ y: 100 }}
          animate={{ y: 0 }}
          className="bg-card border-t border-border rounded-t-3xl p-4 max-h-[40vh] overflow-y-auto"
        >
          <h3 className="text-lg font-bold mb-3">Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù…Ø¶Ø§ÙØ© ({addedItems.length})</h3>
          <div className="space-y-2">
            {addedItems.map((item, i) => (
              <div key={i} className="bg-muted rounded-xl p-3 text-sm font-medium flex items-center gap-2">
                <span>{item}</span>
              </div>
            ))}
          </div>
          <p className="text-xs text-muted-foreground mt-3 text-center">Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø§ÙŠÙƒ Ù„Ø¥Ø¶Ø§ÙØ© Ù…Ù†ØªØ¬ Ø¢Ø®Ø±</p>
        </motion.div>
      )}
    </motion.div>
  );
};

export default VoiceSearch;
